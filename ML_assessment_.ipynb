{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Assessment 2\n",
    "\n",
    "Through the following notebook, you will be tasked with **implementing** two different classification approaches: **k Nearest Neighbours** and **Decision Trees**. You will apply these to two different datasets, evaluate the produced models and analyse their performance.\n",
    "\n",
    "This will be done through several different tasks and sub-tasks:\n",
    "- [Dataset](#Dataset)\n",
    "    - [Task 1: Dataset statistics **(10\\%)**](#Task-1---Dataset-statistics)\n",
    "- [k Nearest Neigbours](#k-Nearest-Neigbours)\n",
    "    - [Task 2.1: Euclidean distance **(10\\%)**](#Task-2.1---Euclidean-distance)\n",
    "    - [Task 2.2: kNN classifier **(20\\%)**](#Task-2.2---kNN-classifier)\n",
    "- [Decision Trees](#Decision-Trees)\n",
    "    - [Task 3.1: Entropy and Information Gain **(10\\%)**](#Task-3.1---Entropy-and-Information-Gain)\n",
    "    - [Task 3.2: Decision Tree classifier **(30\\%)**](#Task-3.2---Decision-Tree-classifier)\n",
    "- [Model evaluation and analysis](#Model-evaluation-and-analysis)\n",
    "    - [Task 4.1: Evaluation **(10\\%)**](#Task-4.1---Evaluation)\n",
    "    - [Task 4.2: Analysis **(10\\%)**](#Task-4.2---Analysis)\n",
    "\n",
    "**Note:** The (%) noted above are out of 100; this will be scaled down to **maximum of 70 marks** for the assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "For this assessment, you will be working with two datasets:\n",
    "- A [numeric-only](#Numerical-data) dataset (crystal systems of Li-ion batteries)\n",
    "- A dataset with [mixed numeric and categorical](#Categorical-data) features (forest cover)\n",
    "\n",
    "For developing your solutions, **you have only been provided with a portion of the samples from each of the dataset** (70% of the [numeric-only](#Numerical-data) and 50% of the [mixed numeric and categorical](#Categorical-data) data). These will be in **identical format** to the full datasets used for evaluating your solutions (there will just be more samples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical data\n",
    "\n",
    "The main part of the assessment will be done on the dataset containing only numerical features describing the physical and chemical properties of the Li-ion battery, which can be classified on the basis of their crystal system. Three major classes of crystal systems are: _monoclinic_, _orthorhombic_ and _triclinic_. (The dataset for this assessment has been adapted from the full dataset which can be found [here](https://www.kaggle.com/datasets/divyansh22/crystal-system-properties-for-liion-batteries\n",
    "\n",
    "Each sample corresponds to the properties of a battery, and consists of following features:\n",
    "\n",
    "| Feature Name      | Value | Description |\n",
    "| :---------------- | :----- | ----------- |\n",
    "| `Formation Energy`       | `float`: eV | Formation energy of the material. |\n",
    "| `E Above Hull` | `float`: eV | Energy of decomposition of material into most stable ones. |\n",
    "| `Band Gap` | `float`: eV | Band gap. |\n",
    "| `Nsites` | `int`: count | Number of atoms in the unit cell of the crystal. |\n",
    "| `Density` | `float`: gm/cc | The density of bulk crystalline materials. |\n",
    "| `Volume` | `float` | The unit cell volume of the material. |\n",
    "\n",
    "The goal for the assessment is to predict whether the crystal system of the battery is _monoclinic_, _orthorhombic_ or _triclinic_, which provides a classification for each sample:\n",
    "\n",
    "| Class      | Value | Description |\n",
    "| :---------------- | :----- | ----------- |\n",
    "| `Crystal System`  | `string`: class designation | Class of the crystal system (three different values). |\n",
    "\n",
    "\n",
    "This dataset will be used for the developmet and testing of both the [kNN](#k-Nearest-Neigbours) and [Decision Tree](#Decision-Trees) classifier, as well as for the [evaluation](#Task-4.1---Evaluation) of both of the classification approaches.\n",
    "\n",
    "The following cell loads the dataset, and splits the samples randomly, using  $80\\%$ of samples for training and $20\\%$ for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import count\n",
    "\n",
    "numerical_data = pd.read_csv(r'batteries.csv')\n",
    "\n",
    "print(\"The dataset consists of {} samples\".format(len(numerical_data)))\n",
    "print(\"The numerical data loaded consists of following columns:\\n{}\".format(\n",
    "    \"\\n\".join([\"\\tColumn {}: {}\".format(i, x) for i, x in enumerate(numerical_data.columns)])))\n",
    "print(\"An example sample:\\n{}\".format(\n",
    "    \"\\n\".join([\"\\tFeature {}: {}={}\".format(i, x, v) for i, (x, v) in \n",
    "               enumerate(zip(numerical_data.columns, numerical_data.loc[0, :])) if not x == 'Crystal System'])))\n",
    "print('\\tClass (Family): {}'.format(numerical_data.loc[0, 'Crystal System']))\n",
    "\n",
    "# We split the dataset into features and the target class, using the 'Family' column as the target:\n",
    "X_nd = numerical_data.loc[:, numerical_data.columns!='Crystal System'].values\n",
    "y_nd = numerical_data['Crystal System'].values\n",
    "\n",
    "# We further split the dataset into a training and testing set\n",
    "X_nd_train, X_nd_test, y_nd_train, y_nd_test = train_test_split(X_nd, y_nd, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(\"The training set consists of {} samples and {} associated ground truth classes\".format(len(X_nd_train),\n",
    "                                                                                             len(y_nd_train)))\n",
    "print(\"The test set consists of {} samples and {} associated ground truth classes\".format(len(X_nd_test),\n",
    "                                                                                             len(y_nd_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical data\n",
    "\n",
    "The second dataset for this assessment contains a mix of numerical and categorical features, with the goal of predicting the forest cover type. The data used in this assessment is adapted from a full dataset provided [here](https://archive.ics.uci.edu/ml/datasets/Covertype) (Jock A. Blackard and Colorado State University).\n",
    "\n",
    "Each sample corresponds to a 30x30 meter cell, and consists of cartographic variables only (i.e. it does not rely on any remotely sensed imaging data), derived from from US Geological Survey (USGS) and USFS data. Each sample consists of the following features (categorical features can be distinguished by being encoded as a string rather tha a numer):\n",
    "\n",
    "| Feature Name      | Value | Description |\n",
    "| :---------------- | :----- | ----------- |\n",
    "| `Elevation`       | `float`: kilometers | Elevation |\n",
    "| `Aspect`   | `int`: degrees azimut | Aspect in degreez azimuth |\n",
    "| `Slope`      | `int`: degrees | Slope in degrees |\n",
    "| `Horizontal_Distance_To_Hydrology`   | `float`: kilometers | Horiz. distance to nearest surface water feature        |\n",
    "| `Vertical_Distance_To_Hydrology`   | `float`: kilometers | Vert. distance to nearest surface water feature        |\n",
    "| `Horizontal_Distance_To_Roadways`     | `float`: kilometers | Hor. distance to nearest roadway       |\n",
    "| `Hillshade_9am`   |`int`: $0 \\dots 255 $|  Hillshade index at 9am, summer solstice        |\n",
    "| `Hillshade_Noon`      |`int`: $0 \\dots 255 $| Hillshade index at noon, summer solstice       |\n",
    "| `Hillshade_3pm`   |`int`: $0 \\dots 255 $| Hillshade index at 3pm, summer solstice        |\n",
    "| `Horizontal_Distance_To_Fire_Points`  | `float`: kilometers | Horiz. distance to nearest wildfire ignition point        |\n",
    "| `Wilderness_Area`   | `string`: name | Wilderness area name (4 different values)       |\n",
    "| `Soil_Type`   |`string`: code| Soil type code (40 different values)       |\n",
    "\n",
    "The goal of this dataset is to predict the forrest cover type for each 30x30 meter cell. A class, corresponding to the forest cover type, is associated to each sample:\n",
    "\n",
    "| Class      | Value | Description |\n",
    "| :---------------- | :----- | ----------- |\n",
    "| `Cover_Type`       | `string`: name | Forest cover type designation (7 different values). |\n",
    "\n",
    "\n",
    "**Note:** Tackling the categorical dataset is a **stretch task** for this assessment. It will be used in the development and testing of the [Decision Tree](#Decision-Trees) classifier, as well as for their [evaluation](#Task-4.1---Evaluation). Tackling this data will **require you to implement a** `DecisionTree` **from scratch**, as `sklearn` **does not provide this functionality**.\n",
    "\n",
    "The following cell loads the dataset, and splits the samples randomly, using  $80\\%$ of samples for training and $20\\%$ for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_data = pd.read_csv(r'forestcover.csv')\n",
    "\n",
    "print(\"The dataset consists of {} samples\".format(len(categorical_data)))\n",
    "print(\"The numerical data loaded consists of following columns:\\n{}\".format(\n",
    "    \"\\n\".join([\"\\tColumn {}: {}\".format(i, x) for i, x in enumerate(categorical_data.columns)])))\n",
    "print(\"An example sample:\\n{}\".format(\n",
    "    \"\\n\".join([\"\\tFeature {}: {}={}\".format(i, x, v) for i, (x, v) in \n",
    "               enumerate(zip(categorical_data.columns, categorical_data.loc[0, :])) if not x == 'Cover_Type'])))\n",
    "print('\\tClass (Cover_Type): {}'.format(categorical_data.loc[0, 'Cover_Type']))\n",
    "\n",
    "# We split the dataset into features and the target class, using the 'Cover_Type' column as the target:\n",
    "X_cd = categorical_data.loc[:, categorical_data.columns!='Cover_Type'].values\n",
    "y_cd = categorical_data['Cover_Type'].values\n",
    "\n",
    "\n",
    "# We further split the dataset into a training and testing set\n",
    "X_cd_train, X_cd_test, y_cd_train, y_cd_test = train_test_split(X_cd, y_cd, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(\"The training set consists of {} samples and {} associated ground truth classes\".format(len(X_cd_train),\n",
    "                                                                                             len(y_cd_train)))\n",
    "print(\"The test set consists of {} samples and {} associated ground truth classes\".format(len(X_cd_test),\n",
    "                                                                                             len(y_cd_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - Dataset statistics\n",
    "#### 10% marks\n",
    "\n",
    "To handle the data for the classification tasks, implement functions that will assist in querying some basic information about the dataset you are handling.\n",
    "\n",
    "Given a set of M samples $\\mathbf{x} = \\{\\mathbf{x}_i\\} \\forall i=1..M$ with n features each $\\mathbf{x}_i = \\{x_{1,i}, \\dots, x_{n,i}\\}$, and the corresponding ground truth labels $\\mathbf{y} = \\{y_i\\} \\forall i=1..M$, implement two functions:\n",
    "\n",
    "- `class_probabilities(y)` : calcualtes the class probabilities from the list of ground truth labels\n",
    "\n",
    "    *Inputs:*<br>\n",
    "    `y`: The list of ground truth labels for a dataset<br>\n",
    "    \n",
    "    *Returns:*<br>\n",
    "    A dictionary of class labels and their probabilities (i.e. the frequency of that class in the dataset)\n",
    "\n",
    "    *Example* :\n",
    "    ```python\n",
    "    y = [1, 0, 0, 0, 1, 2, 1, 1, 2, 1]\n",
    "    print(class_probabilities(y))\n",
    "    ```\n",
    "    *Example output*:<br>\n",
    "    `{0: 0.3, 1: 0.5, 2: 0.2}`\n",
    "    \n",
    "    *Note:* Python dictionaries are unordered, so running this example might result in a different order of keys in the output, for example: `{2: 0.2, 0: 0.3, 1: 0.5}`<br><br>\n",
    "   \n",
    "- `most_common_class` : finds the most common class from the list of ground truth class labels.\n",
    "\n",
    "    *Inputs:*<br>\n",
    "    `y`: the list of ground truth labels for a dataset<br>\n",
    "    \n",
    "    *Returns:*<br>\n",
    "    the label of the most common class represented in the dataset.\n",
    "    \n",
    "    *Example*:\n",
    "    ```python\n",
    "    y = [1, 0, 0, 0, 1, 2, 1, 1, 2, 1]\n",
    "    print(most_common_class(y))\n",
    "    ```\n",
    "    *Example output*:<br>\n",
    "    `1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SOLUTION CELLS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_probabilities(y):\n",
    "    ################################\n",
    "    ####### YOUR CODE HERE #########\n",
    "    ################################\n",
    "\n",
    "    return {} #  you should probably replace this line\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_class(y):\n",
    "    ################################\n",
    "    ####### YOUR CODE HERE #########\n",
    "    ################################\n",
    "\n",
    "    return 0 # you should probably replace this line\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TESTING CELLS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unq, cnt = np.unique(y_nd, return_counts=True)\n",
    "print(\"All unique class labels and counts from numerical-only dataset: {}\".format(\n",
    "    ' '.join(['{}: {}'.format(v,c) for v, c in zip(unq, cnt)])))\n",
    "print(\"All classes and their probabilities:\\n{}\".format(\n",
    "    \"\\n\".join([\"\\t{}: {}\".format(c, p) for c, p in class_probabilities(y_nd).items()])))\n",
    "print(\"Most common class in the numerical-only dataset: {}\".format(most_common_class(y_nd)))\n",
    "print(\"\\n\")\n",
    "\n",
    "unq, cnt = np.unique(y_nd_train, return_counts=True)\n",
    "print(\"All unique class labels for the numerical-only training set: {}\".format(\n",
    "    ' '.join(['{}: {}'.format(v,c) for v, c in zip(unq, cnt)])))\n",
    "print(\"All classes and their probabilities (num-only training set):\\n{}\".format(\n",
    "    \"\\n\".join([\"\\t{}: {}\".format(c, p) for c, p in class_probabilities(y_nd_train).items()])))\n",
    "print(\"Most common class in the num-only training set: {}\".format(most_common_class(y_nd_train)))\n",
    "print(\"\\n\")\n",
    "\n",
    "unq, cnt = np.unique(y_nd_test, return_counts=True)\n",
    "print(\"All unique class labels for the numerical-only testing set: {}\".format(\n",
    "    ' '.join(['{}: {}'.format(v,c) for v, c in zip(unq, cnt)])))\n",
    "print(\"All classes and their probabilities (num-only tests set):\\n{}\".format(\n",
    "    \"\\n\".join([\"\\t{}: {}\".format(c, p) for c, p in class_probabilities(y_nd_test).items()])))\n",
    "print(\"Most common class in the num-only test set: {}\".format(most_common_class(y_nd_test)))\n",
    "print(\"\\n\")\n",
    "\n",
    "y_test = [1, 0, 0, 0, 1, 2, 1, 1, 2, 1]\n",
    "print(\"All class labels for a toy set: {}\".format(y_test))\n",
    "print(\"All classses and their probabilities for the toy set:\\n{}\".format(\n",
    "    \"\\n\".join([\"\\t{}: {}\".format(c, p) for c, p in class_probabilities(y_test).items()])))\n",
    "print(\"Most common class in the toy set: {}\".format(most_common_class(y_test)))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"All classes and their probabilities from the categorical dataset:\\n{}\".format(\n",
    "    \"\\n\".join([\"\\t{}: {:.3f}\".format(c, p) for c, p in class_probabilities(y_cd).items()])))\n",
    "print(\"Most common class in the categorical dataset: {}\".format(most_common_class(y_cd)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k Nearest Neighbours\n",
    "\n",
    "For the first part of the assessment, you are required to implement **k Nearest Neigbours**. A key concept for kNN (and many different machine learning algorithms) is that of **distance**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1 - Euclidean distance\n",
    "#### 10% marks\n",
    "\n",
    "One of the most commonly used distance metrics is the Euclidean distance. The Euclidean distance between two points in the Euclidean space (also known as $L_2$ norm) is defined as the length of the line segment between those two points. For example, if we have two points in 2D space (i.e. two samples consisting of two features), $\\mathbf{x}_0 = \\{x_{0,0}, x_{0,1}\\}$ and $\\mathbf{x}_1 = \\{x_{1,0}, x_{1,1}\\}$, we can calculate the distance as:\n",
    "\n",
    "\\begin{equation*}\n",
    "d_{\\texttt{Euclidean}} = \\sqrt{(x_{0,0} - x_{1,0})^2 + (x_{0,1} - x_{1,1})^2}\n",
    "\\end{equation*}\n",
    "\n",
    "In other words, we need to calculate the difference between the first features of the two samples, the difference between the second features of the two samples, then square each of the differences, sum those squares, and calculate the square root of the resulting sum.\n",
    "\n",
    "In general, when we are dealing with points in nD space (corresponding to samples with n features) of the form $\\mathbf{x}_i = \\{x_{0,i}, x_{1,i}, \\dots, x_{n,i}\\}$, the procedure is very similar. To calculade the Euclidean disatnce, you need to calculate the difference between the corresponding features of two samples, square each of the differences, and calculate the square root of the resulting sum:\n",
    "\n",
    "\\begin{equation*}\n",
    "d_{\\texttt{Euclidean}} = \\sqrt{\\sum_i{(x_{0,i} - x_{1,i})^2}}\n",
    "\\end{equation*}\n",
    "\n",
    "Implement the Euclidean distance as a Python function:\n",
    "- `euclidean_distance`: calculates the Euclidean distance between two n-dimensional samples\n",
    "\n",
    "    *Inputs:*<br>\n",
    "    `x1`: An n-dimensional sample. This either a list of length $n$, or a `numpy.array` of dimensions `(n,)`<br>\n",
    "    `x2`: An n-dimensional sample. This either a list of length $n$, or a `numpy.array` of dimensions `(n,)`<br>\n",
    "\n",
    "    *Returns*<br>\n",
    "    The Euclidean distance between `x1` and `x2`.<br>\n",
    "    \n",
    "    *Example:*\n",
    "\n",
    "    ```python\n",
    "    x1 = [7, -1]\n",
    "    x2 = [4, 3]\n",
    "    print(euclidean_distance(x1, x2)\n",
    "    ```\n",
    "    *Example output:*<br>\n",
    "    `5.0`\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SOLUTION CELL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x1, x2):\n",
    "                \n",
    "    ################################\n",
    "    ####### YOUR CODE HERE #########\n",
    "    ################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TESTING CELL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [7, -1]\n",
    "b = [4, 3]\n",
    "print(\"Euclidean distance between {} ({}D) and {} ({}D) is {}\".format(\n",
    "    a, len(a), b, len(b), euclidean_distance(a,b)))\n",
    "a = [1, 2]\n",
    "b = [3, 4]\n",
    "print(\"Euclidean distance between {} ({}D) and {} ({}D) is {:.3f}\".format(\n",
    "    a, len(a), b, len(b), euclidean_distance(a,b)))\n",
    "a = [4.2, 3.6, 1.0]\n",
    "b = [5.7, 2.8, -1.5]\n",
    "print(\"Euclidean distance between {} ({}D) and {} ({}D) is {:.3f}\".format(\n",
    "    a, len(a), b, len(b), euclidean_distance(a,b)))\n",
    "a = np.random.rand(20)\n",
    "b = np.random.rand(20)\n",
    "print(\"Euclidean distance between {} ({}D) and {} ({}D) is {:.3f}\".format(\n",
    "    a, len(a), b, len(b), euclidean_distance(a,b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2 - kNN classifier\n",
    "#### 20% marks\n",
    "\n",
    "K nearest neighbours classifier will predict the class of a sample based on the class label of its $k$ nearest neigbours, according to a given distance metric. Implement `kNN` classifier which works on samples with numerical features, and relies on the Euclidean distance, as a Python class implementing the following member functions:\n",
    "\n",
    "- `__init__(self, k = 5, distance = euclidean_distance)`: class constructor\n",
    "\n",
    "    *Inputs:*<br>\n",
    "    `k` : The number of neigbours to be considered by the classification model <br>\n",
    "    `distance`: Tunction which is used to calculate the distance between samples (you will use the Euclidean distance implemented in the previous task)<br><br>\n",
    "    \n",
    "- `fit(self, X, y)`: member function used to train the classifier (fit the model to the data)\n",
    "\n",
    "    *Inputs:*<br>\n",
    "    `X`: The dataset samples. This is either a list of $M$ lists of length $n$, or a `numpy.array` of dimensions `(M, n)`<br>\n",
    "    `y`: The dataset labels. This is either a list of length $M$, or a `numpy.array` of dimensions `(M,)`<br><br>\n",
    "    \n",
    "    *Returns:*<br>\n",
    "    The trained classifier model.<br><br>\n",
    "    \n",
    "- `predict(self, X)`: member function used to predict the classes of samples `X`\n",
    "\n",
    "    *Inputs:*<br>\n",
    "    `X`: The samples for which to predict a class. If this is a single sample, then `X` is either a list of length $n$, or a `numpy.array` of dimensions `(n,)`. If this is a set of samples, then `X` is either a list of $M$ lists of length $n$, or a `numpy.array` of dimensions `(M, N)`<br>\n",
    "    \n",
    "    *Returns:*<br>\n",
    "    Predicted class for the samples of X. If `X` was a single sample, then the output is a single class label. If `X` was a set of samples, then the output is a `numpy.array` of dimensions `(n,`)<br>\n",
    "    \n",
    "    *Note:*<br>\n",
    "    The provided code outline already handles the case where `X` is a set of samples (by running on each sample separately). You need write the main logic of this function, i.e. calculating the prediction for a single sample.<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SOLUTION CELL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class knn:\n",
    "    def __init__(self, k = 5, distance = euclidean_distance):\n",
    "        \n",
    "        ################################\n",
    "        ####### YOUR CODE HERE #########\n",
    "        ################################\n",
    "       \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        ################################\n",
    "        ####### YOUR CODE HERE #########\n",
    "        ################################\n",
    "\n",
    "        return self # this should probably be the last line in your fit function\n",
    "            \n",
    "    def predict(self, X):\n",
    "        \n",
    "        # the fololwing block of code handles lists/arrays containing multiple samples\n",
    "        X = np.array(X)\n",
    "        if len(X.shape) >= 2:\n",
    "            return np.array([self.predict(x) for x in X])\n",
    "        \n",
    "        # in the following section, you can assume that X is a single n-dimensional sample:\n",
    "        ################################\n",
    "        ####### YOUR CODE HERE #########\n",
    "        ################################\n",
    "\n",
    "        return 0 # you may replace this line\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TESTING CELL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the classifier with k=3 (using 9 neigbours)\n",
    "classifier = knn(k=9)\n",
    "# Fit the classifier to the training set\n",
    "classifier.fit(X_nd_train, y_nd_train)\n",
    "\n",
    "# Predict the classification for some samples to the testing set\n",
    "for (sample, prediction, truth) in zip(X_nd_test[3:10], classifier.predict(X_nd_test[3:10]), y_nd_test[3:10]):\n",
    "    # Print the sample, predicted class and ground truth\n",
    "    print(\"Sample: {}\\n\\tPredicted class: {}\\n\\tTrue class: {}\".format(sample, prediction, truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "For the second part of the assignment, you are expected to implement a decision tree classifier. A decision tree models the data as a series of decisions based on the values of different features of the sample. The predictions are made in an interpretable fashion, where the decision is made by considering different sample features, and their values, until the new sample is grouped with similar samples presented during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.1 - Entropy and Information Gain\n",
    "#### 10% marks\n",
    "\n",
    "Important concepts in decision trees are **entropy** and **information gain**. **Entropy** is a measure of the variance in the data, of how \"unpredictable\" the dataset is:\n",
    "\n",
    "- If a dataset consists only of samples with the same label (e.g. $\\{\\blacksquare,\\blacksquare,\\blacksquare,\\blacksquare,\\blacksquare,\\blacksquare\\}$), the entropy will be zero (the data is predictable).\n",
    "- If a dataset consists of an equal amount of samples from two classes, (e.g. $\\{\\blacksquare,\\triangle,\\triangle,\\blacksquare,\\triangle,\\blacksquare\\}$), the entropy will be one (the data is unpredictable).\n",
    "- If the class distribution in the dataset lies somewhere between these two extremes, the entropy will be between one and zero.\n",
    "- Entropy also increases as the number of different classes increases.\n",
    "\n",
    "Given $c$ classes, and their associated probabilities (frequencies) in the datasets, $p_i \\forall i \\in 0..c$, the entropy is calculated as:\n",
    "\n",
    "\\begin{equation*}\n",
    "E = -\\sum_i p_i log_2(p_i).\n",
    "\\end{equation*}\n",
    "\n",
    "Implement a function `entropy` which calculates the entropy of a set of class labels from the list of their associated probabilities:\n",
    "\n",
    "- `entropy(p_per_class)`: calculates the entropy of a set of class probabilities\n",
    "\n",
    "    *Inputs:*<br>\n",
    "    `p_per_class`: A list of $c$ probabilities, one for each class in the dataset. This either a list of length $c$, or a `numpy.array` of dimensions `(c,)`<br>\n",
    "\n",
    "    *Returns:*<br>\n",
    "    The entropy of a set with class probabilities given in `p_per_class`.<br>\n",
    "    \n",
    "    *Note:*<br>\n",
    "    You do not need to check if the list of probabilities given is correct; i.e. you may assume that all the probabilities in the list are strictly greater than zero, and that the sum of all the class probabilities equals one.\n",
    "    \n",
    "    *Example:*\n",
    "\n",
    "    ```python\n",
    "    probabilities = [0.5, 0.5]\n",
    "    print(entropy(probabilities))\n",
    "    ```\n",
    "    *Example output:*<br>\n",
    "    `1.0`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SOLUTION CELL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(p_per_class):\n",
    "    ################################\n",
    "    ####### YOUR CODE HERE #########\n",
    "    ################################\n",
    "\n",
    "    return 0 # you may replace this line\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TESTING CELL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Entropy of a set with only one class: {}\".format(entropy([1.0])))\n",
    "print(\"Entropy of a set with two equally probable classes: {}\".format(entropy([0.5, 0.5])))\n",
    "print(\"Entropy of a set with four equally probable clasess: {}\".format(entropy([0.25, 0.25, 0.25, 0.25])))\n",
    "print(\"Entropy of a set with four classes with different probabilities: {:.3f}\".format(\n",
    "    entropy([0.2, 0.3, 0.4, 0.1])))\n",
    "print(\"Entropy of the numerical (batteries) dataset: {:.3f}\".format(\n",
    "    entropy(list(class_probabilities(y_nd).values()))))\n",
    "print(\"Entropy of the categorical (forest cover) dataset: {:.3f}\".format(\n",
    "    entropy(list(class_probabilities(y_cd).values()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **information gain** describes how much variance was lost by dividing a set into parts, i.e. how much more \"predictable\" the parts are from the whole.\n",
    "\n",
    "For example, if we have a dataset $d=\\{\\blacksquare,\\triangle,\\triangle,\\blacksquare,\\triangle,\\blacksquare,\\triangle,\\blacksquare\\}$ (which is \"maximally unpredictable\", so we can calculate $E(d) = 1$), we can:\n",
    "- split it into $d_1=\\{\\blacksquare,\\blacksquare,\\blacksquare,\\blacksquare\\}$ and $d_2=\\{\\triangle, \\triangle, \\triangle, \\triangle\\}$.\n",
    "\n",
    "    Both of $d_1$ and $d_2$ are \"very predictable\" ($E(d_1) = E(d_2) = 0$), both subsets consist of one class only). The resulting information gain is large (we go from unpredictable to predictable, so we gain information):\n",
    "    \n",
    "    $I = E(d) - (0.5E(d_1) + 0.5E(d_2) = 1 - (0+0) =1$\n",
    "    \n",
    "- split it into $d_1=\\{\\blacksquare,\\triangle,\\triangle,\\blacksquare\\}$ and $d_2=\\{\\triangle,\\blacksquare,\\triangle,\\blacksquare\\}$.\n",
    "\n",
    "    Both of $d_1$ and $d_2$ are \"very unpredictable\" ($E(d_1) = E(d_2) = 1$), both subsets have the same amount of samples from each of the two classes). The resulting information gain is small (we start from an unpredictable dataset, and end with two unpredictable subsets, so we do not gain information):\n",
    "\n",
    "    $I = E(d) - (0.5E(d_1) + 0.5E(d_2) = 1 - (0.5\\times1+0.5\\times1) =0$\n",
    "    \n",
    "<br>\n",
    "In general, if we have a dataset $d$ containing $|d|$ samples, and we split it into $s$ subsets $d_i \\forall i=1..s$, each of size $|d_i|$, the information gain of this split is calculated as:\n",
    "\n",
    "\\begin{equation*}\n",
    "    I = E(d) - \\sum_{i=0}^s \\frac{|d_i|}{|d|}E(d_i)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2 - Decision Tree classifier\n",
    "#### 30% marks\n",
    "\n",
    "In each decision node of a decision tree, this classifier splits the dataset into two or more parts according to a value of a certain feature in the dataset.\n",
    "\n",
    "Given a set of M samples $\\mathbf{x} = \\{\\mathbf{x}_i\\} \\forall i=1..M$ with n features each $\\mathbf{x}_i = \\{x_{1,i}, \\dots, x_{n,i}\\}$, we could decide to split the dataset at the $j^{\\texttt{th}}$ (numerical) feature at value $v$. This would mean splitting the dataset into:\n",
    "- the subset $\\mathbf{x_{<}} = \\{\\mathbf{x}_i | x_{j,i} < v\\}$, which contains all the samples with the $j^{\\texttt{th}}$ smaller than $v$ and\n",
    "- the subset $\\mathbf{x_{\\geq}} = \\{\\mathbf{x}_i | x_{j,i} \\geq v\\}$, which contains all the samples with the $j^{\\texttt{th}}$ greater or equal than $v$.\n",
    "\n",
    "Similarly, we could decide to split a dataset at the $j^{\\texttt{th}}$ feature which is categorical. If the $j^{\\texttt{th}}$ feature of a sample $\\mathbf{x}_i$ can hold values $\\{\\texttt{child}, \\texttt{teen}, \\texttt{adult}\\}$, the resulting subsets would be:\n",
    "- the subset $\\mathbf{x_{\\texttt{child}}} = \\{\\mathbf{x}_i | x_{j,i} = \\texttt{child}\\}$, which contains all the samples with the feature $j^{\\texttt{th}}$ equal to $\\texttt{child}$, \n",
    "- the subset $\\mathbf{x_{\\texttt{teen}}} = \\{\\mathbf{x}_i | x_{j,i} = \\texttt{teen}\\}$, which contains all the samples with the feature $j^{\\texttt{th}}$ equal to $\\texttt{teen}$ and\n",
    "- the subset $\\mathbf{x_{\\texttt{adult}}} = \\{\\mathbf{x}_i | x_{j,i} = \\texttt{adult}\\}$, which contains all the samples with the feature $j^{\\texttt{th}}$ equal to $\\texttt{adult}$.\n",
    "\n",
    "In each node of the decision tree, the dataset is split according to the attribute $j$ which results in **the highest information gain** after the split. For categorical features, there is only one possible split (each category becomes a subset). For numerical features, it is neccessary to check all the possible values of split. For example, if the $j^{\\texttt{th}}$ in the dataset has appeared with the values of $\\{1, 1.5, 2.7, 3.2, 5\\}$, you need to calculate the information gain for splitting the dataset at $v=1.5$ (into $\\mathbf{x_{< 1.5}}$ and $\\mathbf{x_{\\geq 1.5}}$), $v=2.7$, $v=3.2$, $v=5$.\n",
    "\n",
    "The splitting continues until each node contains only samples of a single class, or a stopping criterion is reached. If a node contains training samples of more than one class, it returns the label of the majority (most probable) class as its decision.\n",
    "\n",
    "Implement a `DecisionTree` classifier which works on samples with both numerical and categorical features as a Python class implementing the following member functions:\n",
    "\n",
    "- `__init__(self, max_depth = -1, min_samples_per_node = 1)`: class constructor\n",
    "\n",
    "    *Inputs:*<br>\n",
    "    `max_dept` : The maximal depth of the tree (`max_depth == 0` corresponds to a decision tree with only the root node. `max_depth == -1` means no limit to the depth of the tree) <br>\n",
    "    `min_samples_per_node`: The minimal number of samples contained in a terminal (decision) node. If a split would cause one of the subsets to have less than `min_samples_per_node` samples, the split is not performed. <br><br>\n",
    "    \n",
    "- `fit(self, X, y)`: member function used to train the classifier (fit the model to the data)\n",
    "\n",
    "    *Inputs:*<br>\n",
    "    `X`: The dataset samples. This is either a list of $M$ lists of length $n$, or a `numpy.array` of dimensions `(M, n)`<br>\n",
    "    `y`: The dataset labels. This is either a list of length $M$, or a `numpy.array` of dimensions `(M,)`<br>\n",
    "    \n",
    "    *Returns:*<br>\n",
    "    The trained classifier model.<br><br>\n",
    "    \n",
    "- `predict(self, X)`: member function used to predict the classes of samples `X`\n",
    "\n",
    "    *Inputs:*<br>\n",
    "    `X`: The samples for which to predict a class. If this is a single sample, then `X` is either a list of length $n$, or a `numpy.array` of dimensions `(n,)`. If this is a set of samples, then `X` is either a list of $M$ lists of length $n$, or a `numpy.array` of dimensions `(M, N)`<br>\n",
    "    \n",
    "    *Returns:*<br>\n",
    "    Predicted class for the samples of X. If `X` was a single sample, then the output is a single class label. If `X` was a set of samples, then the output is a `numpy.array` of dimensions `(n,`)<br>\n",
    "    \n",
    "    *Note:*<br>\n",
    "    The provided code outline already handles the case where `X` is a set of samples (by running on each sample separately). You need write the main logic of this function, i.e. calculating the prediction for a single sample.<br><br>\n",
    "    \n",
    "*Note:* Your implementation will be tested in two parts. Firstly, it will be tested only on a dataset containing numerical values. Secondly, it will also be tested on a dataset containing a mix of categorical and numerical values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SOLUTION CELL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, max_depth = -1, min_samples_per_node = 1):\n",
    "        ################################\n",
    "        ####### YOUR CODE HERE #########\n",
    "        ################################\n",
    "           \n",
    "    def fit(self, X, y):\n",
    "        ################################\n",
    "        ####### YOUR CODE HERE #########\n",
    "        ################################\n",
    "        \n",
    "        return self # you may replace this line\n",
    "               \n",
    "    def predict(self, X):\n",
    "\n",
    "        # the fololwing block of code handles lists/arrays containing multiple samples\n",
    "        X = np.array(X)\n",
    "        if len(X.shape) >= 2:\n",
    "            return np.array([self.predict(x) for x in X])\n",
    "        \n",
    "        # in the following section, you can assume that X is a single n-dimensional sample:\n",
    "        ################################\n",
    "        ####### YOUR CODE HERE #########\n",
    "        ################################\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TESTING CELLS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will test if the classifier implemented model can fit to the [numerical dataset](#Numerical-data), and predict solutions for some of the testing samples (this is not model evaluation yet):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the classifier, requiring at least 3 samples in each node\n",
    "classifier = DecisionTree(min_samples_per_node = 3)\n",
    "# Fit the classifier to the training data\n",
    "classifier.fit(X_nd_train, y_nd_train)\n",
    "# Predict the classification for some samples to the testing set\n",
    "for (sample, prediction, truth) in zip(X_nd_test[3:10], classifier.predict(X_nd_test[3:10]), y_nd_test[3:10]):\n",
    "    # Print the sample, predicted class and ground truth\n",
    "    print(\"Sample: {}\\n\\tPredicted class: {}\\n\\tTrue class: {}\".format(sample, prediction, truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will check if the dataset is able to fit the model to the [dataset with mixed numerical and categorical values](#Categorical-data), and predict solutions for some of the testing samples (this is not model evaluation yet):\n",
    "\n",
    "_**Warning:**_ Executing this cell may take a bit of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the classifier, requiring the decision tree to have no more than 5 levels\n",
    "classifier = DecisionTree(max_depth = 4)\n",
    "# Fit the classifier to the training data\n",
    "classifier.fit(X_cd_train, y_cd_train)\n",
    "\n",
    "# Predict the classification for some samples to the testing set\n",
    "for (sample, prediction, truth) in zip(X_cd_test[3:10], classifier.predict(X_cd_test[3:10]), y_cd_test[3:10]):\n",
    "    # Print the sample, predicted class and ground truth\n",
    "    print(\"Sample: {}\\n\\tPredicted class: {}\\n\\tTrue class: {}\".format(sample, prediction, truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation and analysis\n",
    "\n",
    "Executing all the cells from the previous section correctly only means that your implementation of [kNN classifier](#knn-Classifier) and [Decision Tree classifier](#Decision-Tree-classifier) runs on the provided data. This has still not provided any insight on how well those models represent the data.\n",
    "\n",
    "In this section, you are instead required to calculate some evaluation metrics, and evaluate the produced models on the whole of the held-out data (test set) defined in the [Dataset](#Dataset) section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.1 - Evaluation\n",
    "#### 10% marks\n",
    "\n",
    "You are required to write a function that will calculate different evaluation metrics based on the ground truth labels and the predicted labels. Specifically, write a function:\n",
    "- `evaluate(y_true, y_pred)`: evaluate classification results\n",
    "\n",
    "    *Inputs:*<br>\n",
    "    `y_true` : Ground truth labels for $n$ samples. This is either a list of $n$ elements, or a `numpy.array` of dimensions `(n,)`\n",
    "    `y_pred` : Predicted labels for $n$ samples. This is either a list of $n$ elements, or a `numpy.array` of dimensions `(n,)`\n",
    "    \n",
    "    *Returns:*<br>\n",
    "    A touple `(a, p, r, k)` consisting of the following values:\n",
    "    - `a` : overall accuracy of the predictions\n",
    "    - `p` : a dictionary containing a precision score for each class present in `y_true`\n",
    "    - `r` : a dictionary containing a recall score for each class present in `y_true`\n",
    "    - `k` : Cohen's Kappa metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SOLUTION CELL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def evaluate(y_true, y_pred):\n",
    "    \n",
    "    ################################\n",
    "    ####### YOUR CODE HERE #########\n",
    "    ################################\n",
    "    \n",
    "    return 0,{},{},0 # you may replace this line\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TESTING CELL:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell evaluates your implementation of [kNN classifier](#Task-2.2---kNN-classifier) and [Decision Tree classifier](#Task-3.2---Decision-Tree-classifier) on the numerical dataset defined in the [Dataset](#Dataset) section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_knn = knn(k=5)\n",
    "classifier_knn.fit(X_nd_train, y_nd_train)\n",
    "\n",
    "classifier_dt = DecisionTree(min_samples_per_node = 3)\n",
    "classifier_dt.fit(X_nd_train, y_nd_train)\n",
    "\n",
    "y_knn = classifier_knn.predict(X_nd_test)\n",
    "y_dt = classifier_dt.predict(X_nd_test)\n",
    "\n",
    "a_knn, p_knn, r_knn, k_knn = evaluate(y_nd_test, y_knn)\n",
    "a_dt, p_dt, r_dt, k_dt = evaluate(y_nd_test, y_dt)\n",
    "\n",
    "print(\"Evaluating numerical dataset, using kNN:\")\n",
    "print(\"Accuracy = {:.4f}, Cohen's Kappa = {:.4f}\".format(a_knn, k_knn))\n",
    "for key in p_knn.keys():\n",
    "    print(\"\\tClass {}: precision = {:.2f}, recall = {:.2f}\".format(key, p_knn[key], r_knn[key]))\n",
    "\n",
    "print(\"Evaluating numerical dataset, using DecisionTree:\")\n",
    "print(\"Accuracy = {:.4f}, Cohen's Kappa = {:.4f}\".format(a_dt, k_dt))\n",
    "for key in p_dt.keys():\n",
    "    print(\"\\tClass {}: precision = {:.2f}, recall = {:.2f}\".format(key, p_dt[key], r_dt[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell evaluates your implementation of [Decision Tree classifier](#Decision-Tree-classifier) on the [dataset containing a mixture of numerical and categorical data](#Categorical-data):\n",
    "\n",
    "_**Warning:**_ Executing this cell may take a bit of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_categorical = DecisionTree(max_depth = 4)\n",
    "classifier_categorical.fit(X_cd_train, y_cd_train)\n",
    "\n",
    "y_cd_pred = classifier_categorical.predict(X_cd_test)\n",
    "a_cat, p_cat, r_cat, k_cat = evaluate(y_cd_test, y_cd_pred)\n",
    "\n",
    "print(\"Evaluating categorical dataset, using DecisionTree:\")\n",
    "print(\"Accuracy = {:.4f}, Cohen's Kappa = {:.4f}\".format(a_cat, k_cat))\n",
    "for key in p_cat.keys():\n",
    "    print(\"\\tClass {}: precision = {:.2f}, recall = {:.2f}\".format(key, p_cat[key], r_cat[key]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.2 - Analysis\n",
    "#### 10% marks\n",
    "\n",
    "Answer the following questions in the space provided below (marked as **YOUR ANSWERS**):\n",
    "1. Explain the difference between the different performance metrics calculated for [Task 4.1](#Task-4.1---Evaluation). Which additional metrics could you propose to evaluate the performance of the defined models? Which of the calculated metrics would you chose to report, and why, for the analysis of the two [datasets](#Datasets) used in this assessment?\n",
    "\n",
    "2. In case you were handling a _very large_ amount of data, which of the models do you expect to be larger (i.e. take up more memory)? Which of the models do you expect to train faster? Which of the models do you expect to reach a decision faster? Explain and justify your answers.\n",
    "\n",
    "3. When handling numerical data, what is the role of normalisation? The numerical data used in this assessment was not normalised. If you were to normalise the data before training these classification models, would either of them change how they represent the data (and potentially return different results)?\n",
    "\n",
    "4. For evaluating the performance of the classifiers implemented for this assignment, $80\\%$ of the data was used for training the models, and $20\\%$ for testing. What are the shortcomings of this evaluation strategy, and can you propose and describe a better one?\n",
    "\n",
    "_Note:_ You may use the cell marked as **EXPERIMENTAL CELL** to write any code that could help you answer the above questions, or in general, to experiment with the code produced for this assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTAL CELL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ You may use this cell to write any code which may help you answers the questions above ##############\n",
    "####### Your implementations from this cell will not be assessed, feel free to use it for experimentation ########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### YOUR ANSWERS:\n",
    "\n",
    "1. <font color='red'>Answer to question 1</font> \n",
    "2. <font color='red'>Answer to question 2</font> \n",
    "3. <font color='red'>Answer to question 3</font> \n",
    "4. <font color='red'>Answer to question 4</font> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
